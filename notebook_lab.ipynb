{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1aba5ad",
   "metadata": {},
   "source": [
    "# **Título: Lab2**\n",
    "\n",
    "**Membros da Equipe do Projeto:**\n",
    "    \n",
    "    - Pedro Ulisses \n",
    "    \n",
    "    - Iago Jacob\n",
    "\n",
    "    - Welberson Franklin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2278883b",
   "metadata": {},
   "source": [
    "Primeiramente, importando os módulos que serão utilizados no pré-processamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc3a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Este módulo é para trabalhar os datasets, neste caso de imagens, com a unidade fundamental dos tensores\n",
    "import torch\n",
    "\n",
    "## Esse submódulo de torch é para criar o dataset a partir de uma pasta no computador e depois carregá-lo\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "## Estes módulo é para realizar transformações sobre as imagens\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "## Estes módulos são as redes neurais, já treinadas, que utilizaremos para gerar características para as imagens do dataset\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.models import resnet50, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef215be",
   "metadata": {},
   "source": [
    "Depois, importando-se os utilizados para o restante das atividades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97208c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Este módulo permite a leitura de arquivos no python e operações com caminhos\n",
    "import os\n",
    "\n",
    "## Estes módulos serão utilizados para selecionar os melhores atributos para o posterior treino da AM\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "## Estes módulos serão utilizados para criar as figuras com os boxplots\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Estes módulos serão utilizados para fazer o treinamento dos modelos de AM\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f7b732",
   "metadata": {},
   "source": [
    "        As redes neurais utilizadas para o processamento foram ResNet18 e ResNet50. O motivo pelos quais elas foram escolhidas é para isolar o efeito que a adição de camadas a uma rede neural tem sobre os resultados de acurácia nos testes. Tal efeito pode ser isolado porque as ambas as redes seguem a arquitetura ResNet. \n",
    "\n",
    "Abaixo, temos o trecho de código que faz a extração de atributos das imagens de cada conjunto de dados. Para especificar a rede neural, escrevemos:\n",
    "\n",
    "-  rede_neural = 'rn18' ou 'rn50'\n",
    "\n",
    "Para especificar o conjunto de dados que está sendo pré-processado, escrevemos:\n",
    "\n",
    "- conj_pre_process = 'train' ou \"validation\" ou \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb2a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rede_neural = 'rn18'\n",
    "conj_pre_process = 'train'\n",
    "\n",
    "\n",
    "## Este objeto transform é uma pipeline de ações para padronizar o tipo de imagem do nosso dataset, retornando tensores do torch ao final\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),         \n",
    "    transforms.CenterCrop(224),  \n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "\n",
    "## Classe criada para realizar criar o dataset a partir dos caminhos fornecidos na máquina onde este código é rodado\n",
    "class TxtFileDataset(Dataset):\n",
    "    def __init__(self, txt_file, root_dir, transform=None):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths_and_labels = []\n",
    "\n",
    "        with open(txt_file, 'r') as f:\n",
    "            for line in f:\n",
    "                # Divide cada linha em uma lista com o caminho e com o rótulo, respectivamente\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    path, label = line.split()\n",
    "                    self.image_paths_and_labels.append((path, int(label)))\n",
    "\n",
    "    def __len__(self):\n",
    "        # Retorna o número total de amostras no dataset\n",
    "        return len(self.image_paths_and_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ## Será útil para situações em que precisaremos fazer dataset[idx]\n",
    "\n",
    "        relative_path, label = self.image_paths_and_labels[idx]\n",
    "        \n",
    "        full_image_path = os.path.join(self.root_dir, relative_path)\n",
    "        \n",
    "        # Carrega a imagem usando a biblioteca Pillow (PIL)\n",
    "        # .convert('RGB') garante que a imagem tenha 3 canais\n",
    "        image = Image.open(full_image_path).convert('RGB')\n",
    "\n",
    "        # Aplica as transformações na imagem, se houver\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "################################################################### \n",
    "\n",
    "caminho_arquivo_txt = f'.{os.sep}Dados{os.sep}{conj_pre_process}.txt'        # caminho para o conjunto de dados a ser pré-processado\n",
    "diretorio_raiz_dados = f'.{os.sep}Dados'                                     # caminho para o diretório de Dados\n",
    "\n",
    "################################################################### \n",
    "\n",
    "## Criação do dataset\n",
    "dataset_train = TxtFileDataset(txt_file=caminho_arquivo_txt,\n",
    "                             root_dir=diretorio_raiz_dados,\n",
    "                             transform=transform)\n",
    "\n",
    "## Estabelece-se que será utilizada a CPU para os processos com as redes neurais\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "## Para obtermos um processamento mais rápido, rodaremos as redes neurais em lotes de 16 imagens\n",
    "batch_size = 16\n",
    "\n",
    "data_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "################################################################### \n",
    "\n",
    "## Aqui, escolhemos a rede neural que será utilizada\n",
    "\n",
    "if rede_neural == 'rn18':\n",
    "    resnet = resnet18(weights=ResNet18_Weights.DEFAULT).to(device)\n",
    "elif rede_neural == 'rn50':\n",
    "    resnet = resnet50(weights=ResNet18_Weights.DEFAULT).to(device)\n",
    "else:\n",
    "    raise(NameError('Escolha uma rede neural dentre as duas citadas no texto.'))\n",
    "\n",
    "################################################################### \n",
    "\n",
    "\n",
    "## Estabelecemos que não iremos treinar a rede, mas testá-la, avaliá-la, tomando o seu tensor intermediário logo antes da classificação final\n",
    "resnet.eval()\n",
    "extracted_features = []\n",
    "\n",
    "## Definimos a função hook para extrair o tensor intermediário do processo das redes neurais\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    extracted_features.append(output.detach().cpu())\n",
    "\n",
    "\n",
    "# Registrando o hook na camada 'avgpool'(camada antes da camada de classificação)\n",
    "hook_handle = resnet.avgpool.register_forward_hook(hook_fn)\n",
    "all_labels = []\n",
    "\n",
    "\n",
    "## Aplicação da rede neural sobre as imagens no dataset já carregado\n",
    "with torch.no_grad():\n",
    "    for images, labels in data_loader:\n",
    "        images = images.to(device)\n",
    "        _ = resnet(images)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "## Ajuste da dimensão dos tensores que guardam o resultado intermediário das redes neurais quando alimentadas com o dataset\n",
    "features = torch.cat(extracted_features, dim=0)\n",
    "features = features.view(features.size(0), -1)\n",
    "labels = torch.cat(all_labels)\n",
    "\n",
    "## Salvando os resultados obtidos para acessá-los diretamente depois\n",
    "torch.save({\n",
    "    'features': features,\n",
    "    'labels': labels\n",
    "}, rede_neural+'_'+conj_pre_process+'.pt')\n",
    "\n",
    "\n",
    "print(\"Features extraídas:\", features.shape) \n",
    "print(\"Labels:\", labels.shape) \n",
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96c9967",
   "metadata": {},
   "source": [
    "No trecho de código abaixo, fazemos a seleção dos cinco atributos mais representativos para a rotulação formiga/abelha. Escolhemos a rede neural que produz atributos escrevendo:\n",
    "\n",
    "-  rede_neural = 'rn18' ou 'rn50'\n",
    "\n",
    "Especificamos o conjunto de dados no qual faremos a seleção de cinco atributos escrevendo:\n",
    "\n",
    "- conj_dados_kselect = 'train' ou \"validation\" ou \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07308d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rede_neural = 'rn18'\n",
    "conj_dados_kselect = 'train'\n",
    "\n",
    "# Carrega o dicionário salvo previamente salvo em arquivo\n",
    "dados_carregados = torch.load(rede_neural+'_'+conj_dados_kselect+'.pt')\n",
    "\n",
    "# Acessa os tensores usando as mesmas chaves\n",
    "features = dados_carregados['features']\n",
    "labels = dados_carregados['labels']\n",
    "\n",
    "# Feature extraction\n",
    "test = SelectKBest(score_func=chi2,k=5)\n",
    "fit = test.fit(features, labels)\n",
    "\n",
    "## Com esta função, obtém-se um vetor que mostra quais foram as features selecionadas\n",
    "mask = fit.get_support() \n",
    "print(len(mask))\n",
    "\n",
    "features = fit.transform(features)\n",
    "labels = labels.numpy()\n",
    "\n",
    "\n",
    "## Salvando os resultados obtidos, já no formato de array numpy, para acessá-los diretamente depois\n",
    "from scipy.io import savemat\n",
    "savemat('selected_'+rede_neural+'_'+conj_dados_kselect+'.mat', {'features': features, 'labels':labels, 'mask': mask  })\n",
    "\n",
    "\n",
    "print(\"Features extraídas:\", features.shape) \n",
    "print(\"Labels:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f8dfc1",
   "metadata": {},
   "source": [
    "Definindo-se uma função que gera um box plot para cada um dos cinco atributos, dado o nome de um conjunto de dados cujos atributos foram selecionados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956c45d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "\n",
    "def criar_box_plot(idx, nome_arquivo):\n",
    "\n",
    "    # Carrega o dicionário salvo previamente salvo em arquivo\n",
    "    dados_carregados = loadmat(nome_arquivo)\n",
    "\n",
    "    # Carrega os arrays numpy\n",
    "    features = dados_carregados['features']\n",
    "    labels = dados_carregados['labels'].squeeze()\n",
    "\n",
    "    feature_a_plotar = features[:, idx]\n",
    "\n",
    "    # Dataframe do pandas com duas colunas: uma para os valores da feature e outra para os rótulos.\n",
    "    df = pd.DataFrame({\n",
    "        'feature_value': feature_a_plotar,\n",
    "        'label': labels\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    sns.boxplot(x='label', y='feature_value', data=df)\n",
    "\n",
    "    plt.title(f'Boxplot da Feature {idx} para cada Classe')\n",
    "    plt.xlabel('Classe (Label)')\n",
    "    plt.ylabel(f'Valor da Feature {idx}')\n",
    "    plt.grid(True) # Adiciona uma grade para facilitar a leitura\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216d91d7",
   "metadata": {},
   "source": [
    "Primeiramente, para a rede neural ResNet18, obtém-se os seguintes box plots para os cinco atributos selecionados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0488e228",
   "metadata": {},
   "outputs": [],
   "source": [
    "criar_box_plot(0, 'selected_rn18_train.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "criar_box_plot(1, 'selected_rn18_train.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be58549",
   "metadata": {},
   "outputs": [],
   "source": [
    "criar_box_plot(2, 'selected_rn18_train.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4510d5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criar_box_plot(3, 'selected_rn18_train.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa061a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criar_box_plot(4, 'selected_rn18_train.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d68a363",
   "metadata": {},
   "source": [
    "Desta vez, para a rede neural ResNet50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5338746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criar_box_plot(0, 'selected_rn50_train.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77307b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "criar_box_plot(1, 'selected_rn50_train.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65677e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criar_box_plot(2, 'selected_rn50_train.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9212a2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criar_box_plot(3, 'selected_rn50_train.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criar_box_plot(4, 'selected_rn50_train.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebeac48",
   "metadata": {},
   "source": [
    "        Idealmente, as classes seriam facilmente distinguíveis por um atributo se seus box plots, incluindo os \"whiskers\", não se intersectassem. Isso demonstraria que a distribuição de valores desse atributo para cada uma das classes não tem muitas coincidências para as classes, de modo que elas possam ser distinguíveis. No caso dos box plots mostrados acima, nota-se que aqueles produzidos pelos atributos da ResNet18 têm consideráveis intersecções, sendo a largura interquartis de ambas classes relativamente grandes, de modo a gerar coincidências. Para os box plots do ResNet50, nota-se que em quase todas os atributos há uma classe com largura interquartis relativamente pequena, com menos intersecções entre os box plots de cada classe, de modo que se possa esperar que as previsões do ResNet50 tenham mais acurácia que as do ResNet18."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53faf27d",
   "metadata": {},
   "source": [
    "        Agora, iremos realizar o treinamento de um modelo com diferentes algoritmos, utilizando-se um conjunto de treinamento, outro de validação para o ajuste de hiperparâmetros e outro de teste, para enfim avaliar a acurácia do modelo obtido. Com esses dados de acurácia, será possível não só comparar os algoritmos, mas a forma como a escolha da rede neural do pré-processamento lhes afeta a acurácia.\n",
    "\n",
    "Abaixo, começamos com o algoritmo KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c67af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rede_neural = 'rn18'\n",
    "\n",
    "\n",
    "nome_treino    = rede_neural+'_train.pt'\n",
    "nome_validacao = rede_neural+'_validation.pt'\n",
    "nome_teste = rede_neural+'_test.pt'\n",
    "\n",
    "selecionar_hiper_param = {\n",
    "\n",
    "    1: [ None, 0] , \n",
    "    3: [ None, 0] ,\n",
    "    5: [ None, 0] ,\n",
    "#   valor_k:  Pipeline, acurácia\n",
    "}\n",
    "\n",
    "i_max_acuracia = 1\n",
    "\n",
    "for i in [1, 3, 5]:\n",
    "\n",
    "    pipeline_knn = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('knn', KNeighborsClassifier(n_neighbors=i)) # Exemplo de parâmetros\n",
    "    ])\n",
    "\n",
    "    dados_treino = torch.load(nome_treino)\n",
    "    X_treino = dados_treino['features']\n",
    "    y_treino = dados_treino['labels']\n",
    "\n",
    "    dados_validacao = torch.load(nome_validacao)\n",
    "    X_validacao = dados_validacao['features']\n",
    "    y_validacao = dados_validacao['labels']\n",
    "\n",
    "    ## Faz o treinamento\n",
    "    pipeline_knn.fit(X_treino, y_treino)\n",
    "\n",
    "    ## Calcula a acurácia para o conjunto de validação\n",
    "    previsoes = pipeline_knn.predict(X_validacao)\n",
    "    acuracia = accuracy_score(y_validacao, previsoes)\n",
    "\n",
    "    selecionar_hiper_param[i] = [pipeline_knn, acuracia]\n",
    "\n",
    "    if selecionar_hiper_param[i_max_acuracia][1] < acuracia:\n",
    "        i_max_acuracia = i \n",
    "\n",
    "\n",
    "\n",
    "melhor_knn = selecionar_hiper_param[i_max_acuracia][0]\n",
    "dados_teste = torch.load(nome_teste)\n",
    "X_teste = dados_treino['features']\n",
    "y_teste = dados_treino['labels']\n",
    "previsoes_teste = pipeline_knn.predict(X_teste)\n",
    "acuracia_teste = accuracy_score(y_teste, previsoes_teste)\n",
    "\n",
    "\n",
    "print( f'Para o treino com o conjunto de dados {nome_treino} e validação {nome_validacao}, obteve-se maior acurácia, de {selecionar_hiper_param[i_max_acuracia][1]:.4f} com k={i_max_acuracia}.')\n",
    "print( f'\\n\\nPara o treino com o conjunto de dados {nome_treino} com k={i_max_acuracia}, a acurácia do modelo no conjunto teste foi de {acuracia_teste:.4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e57c8d8",
   "metadata": {},
   "source": [
    "Agora, para o algoritmo AD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68529e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79a32017",
   "metadata": {},
   "source": [
    "Por último, para o algoritmo RF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce09810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3137a52",
   "metadata": {},
   "source": [
    "Enfim, fazendo-se o treinamento e o teste de cada algoritmo, consguimos preencher a tabela de acurácia, a seguir:\n",
    "\n",
    "| | kNN | AD | RF |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Atributos ResNet18** | 0.9118 | <valor acurácia> | <valor acurácia> |\n",
    "| **Atributos ResNet50** | 0.9353 | <valor acurácia> | <valor acurácia> |\n",
    "\n",
    "2. Treinamento dos modelos\n",
    "a) kNN\n",
    "b) AD\n",
    "c) RF\n",
    "3. Teste dos modelos\n",
    "4. Discussões\n",
    "5. Conclusões: Comentários e sugestões sobre o trabalho\n",
    "(complexidade/facilidade, sugestões, etc.).\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
